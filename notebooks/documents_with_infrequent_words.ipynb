{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T20:58:42.417137Z",
     "start_time": "2020-11-01T20:58:42.392592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from expressiveness_benchmark.types import Plan, Task, Language, SourceRange, Program, load_all_programs\n",
    "from code_widget.example import CodeWidget\n",
    "from dataclasses import replace\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T20:58:42.746216Z",
     "start_time": "2020-11-01T20:58:42.727576Z"
    }
   },
   "outputs": [],
   "source": [
    "# CHANGE ME!\n",
    "TASK_ID = 'documents_with_infrequent_words'\n",
    "AUTHOR = 'will'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T19:12:17.789001Z",
     "start_time": "2020-11-11T19:12:17.757800Z"
    }
   },
   "outputs": [],
   "source": [
    "task = Task(\n",
    "    id=TASK_ID,\n",
    "    category=\"Strings\",\n",
    "    name=\"Documents with infrequent words\",\n",
    "    description=\"Find the index of documents that contain a word that appears exactly once in the corpus, \\\n",
    "where a word is a case-sensitive string of characters separated by a space.\",\n",
    "    plan=[],\n",
    "    sample_input={\n",
    "        \"documents\": [\n",
    "            {\"id\": 1, \"text\": \"Hello world\"},\n",
    "            {\"id\": 2, \"text\": \"Hello friend\"},\n",
    "            {\"id\": 3, \"text\": \"friend of the world\"},\n",
    "            {\"id\": 4, \"text\": \"Hola\"}\n",
    "        ]\n",
    "    },\n",
    "    sample_output=[3, 4],\n",
    ")\n",
    "task.save()\n",
    "\n",
    "prototype = Program(\n",
    "    task=TASK_ID,\n",
    "    author=AUTHOR,\n",
    "    language=''    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T19:01:25.024304Z",
     "start_time": "2020-11-11T19:01:24.983425Z"
    }
   },
   "outputs": [],
   "source": [
    "python_imperative = replace(prototype,\n",
    "    language='python-imperative',\n",
    "    source='''def documents_with_infrequent_words(documents):\n",
    "  words = {}\n",
    "  freq = defaultdict(int)\n",
    "  for doc in documents:\n",
    "    words[doc[\"id\"]] = doc[\"text\"].split(\" \")\n",
    "    for word in words[doc[\"id\"]]:\n",
    "      freq[word] += 1\n",
    "      \n",
    "  infrequent_words = set()\n",
    "  for word, count in freq.items():\n",
    "    if count == 1:\n",
    "      infrequent_words.add(word)\n",
    "      \n",
    "  infrequent_docs = []\n",
    "  for doc in documents:\n",
    "    for word in words[doc[\"id\"]]:\n",
    "      if word in infrequent_words:\n",
    "        infrequent_docs.append(doc[\"id\"])\n",
    "        break\n",
    "        \n",
    "  return infrequent_docs''').load_plan()\n",
    "python_imperative.execute(task)\n",
    "python_imperative.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T19:07:15.530800Z",
     "start_time": "2020-11-11T19:07:15.502917Z"
    }
   },
   "outputs": [],
   "source": [
    "python_functional = replace(prototype,\n",
    "    language='python-functional',\n",
    "    source='''def documents_with_infrequent_words(documents):\n",
    "  words = [doc[\"text\"].split(\" \") for doc in documents]\n",
    "  words_flat = [w for ws in words for w in ws]\n",
    "  freq = {\n",
    "    word: words_flat.count(word) \n",
    "    for word in set(words_flat)\n",
    "   }\n",
    "  infrequent_words = set([\n",
    "    word for word, count in freq.items() \n",
    "    if count == 1\n",
    "  ])\n",
    "  infrequent_docs = [\n",
    "    documents[i][\"id\"] for i, ws in enumerate(words) \n",
    "    if len(set(ws) & infrequent_words) > 0\n",
    "  ]\n",
    "  return infrequent_docs''').load_plan()\n",
    "python_functional.execute(task)\n",
    "python_functional.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T19:07:30.453841Z",
     "start_time": "2020-11-11T19:07:30.417934Z"
    }
   },
   "outputs": [],
   "source": [
    "python_pandas = replace(prototype,\n",
    "    language='python-pandas',\n",
    "    source='''def documents_with_infrequent_words(documents):\n",
    "  words = documents.text.str.split(\" \", expand=True)\n",
    "  freq = words.stack().value_counts()\n",
    "  infrequent_words = freq[freq == 1].index.values\n",
    "  infrequent_docs = documents[\n",
    "    np.isin(words.values, infrequent_words)]\n",
    "  return infrequent_docs.id.unique().tolist()''').load_plan()\n",
    "python_pandas.execute(task)\n",
    "python_pandas.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T19:10:57.862879Z",
     "start_time": "2020-11-11T19:10:57.828120Z"
    }
   },
   "outputs": [],
   "source": [
    "sql = replace(prototype,\n",
    "    language='sql',\n",
    "    source='''-- NOTE: SQLite tokenize is case-insensitive by default, \n",
    "-- so this solution is NOT exactly like the others\n",
    "\n",
    "CREATE VIRTUAL TABLE doc_index USING fts4(\n",
    "  text, id, content=documents, tokenize=simple);    \n",
    "INSERT INTO doc_index(doc_index) VALUES('rebuild');\n",
    "CREATE VIRTUAL TABLE words USING fts4aux(doc_index);    \n",
    "\n",
    "SELECT DISTINCT id\n",
    "FROM \n",
    "  documents\n",
    "  CROSS JOIN\n",
    "  (SELECT DISTINCT term\n",
    "   FROM words\n",
    "   WHERE occurrences = 1) unique_words\n",
    "WHERE\n",
    "  (LOWER(text) LIKE '% ' || term || ' %') OR\n",
    "  (LOWER(text) LIKE term || ' %') OR\n",
    "  (LOWER(text) LIKE '% ' || term) OR\n",
    "  (LOWER(text) LIKE term)''').load_plan()\n",
    "sql.execute(task)\n",
    "sql.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T19:08:04.512367Z",
     "start_time": "2020-11-11T19:08:04.383954Z"
    }
   },
   "outputs": [],
   "source": [
    "datalog = replace(prototype,\n",
    "    language='datalog',\n",
    "    source='''.decl substrs(Text:symbol, Idx:number, Len:number)\n",
    "substrs(Text, 0, 1) :- \n",
    "  documents(_, Text), strlen(Text) > 0.\n",
    "substrs(Text, 0, Len+1) :- \n",
    "  substrs(Text, 0, Len), Len + 1 <= strlen(Text).\n",
    "substrs(Text, Idx+1, Len) :- \n",
    "  substrs(Text, Idx, Len), Idx + Len + 1 <= strlen(Text).\n",
    "\n",
    ".decl token(Docid:number, Text:symbol, Idx:number, Word:symbol)\n",
    "token(Docid, Text, Idx, Word) :-\n",
    "  documents(Docid, Text),\n",
    "  substrs(Text, Idx, Len),\n",
    "  Prev = Idx - 1, Next = Idx + Len,\n",
    "  (Prev < 0; \" \" = substr(Text, Prev, 1)),\n",
    "  (Next = strlen(Text); \" \" = substr(Text, Next, 1)),\n",
    "  Word = substr(Text, Idx, Len),\n",
    "  !contains(\" \", Word).\n",
    "\n",
    "documents_with_infrequent_words(Id) :-\n",
    "  documents(Id, _),\n",
    "  token(Id, _, _, Word),\n",
    "  1 = count : token(_, _, _, Word).''').load_plan()\n",
    "datalog.execute(task)\n",
    "datalog.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
